{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentimental_analysis_lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_UTgaSL-4ak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "59bcefc5-284b-4dd2-9285-ab1660675b0e"
      },
      "source": [
        "import numpy\n",
        "import keras\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "print(\"Importing of libraries and IMDB Datset from keras in done..\")"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Importing of libraries and IMDB Datset from keras in done..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_FuoW1Q-4e6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c2398cb6-4535-47ea-9e40-eaa84edfba41"
      },
      "source": [
        "data=keras.datasets.imdb\n",
        "type(data)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "module"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKyNeClZFwqJ",
        "colab_type": "text"
      },
      "source": [
        "CHECKING KEYS AND VALUES OF DICTONERY WORD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEFU3Y1o-4iz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "0a6ec829-0399-4417-a46e-55a4002a26df"
      },
      "source": [
        "word=data.get_word_index()\n",
        "print(type(word))\n",
        "for i,j in word.items():\n",
        "  if j==0:\n",
        "    print(i,j)\n",
        "  if j==1:\n",
        "    print(i,j)\n",
        "  if j==2:\n",
        "    print(i,j)\n",
        "  if j==3:\n",
        "    print(i,j)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "a 3\n",
            "the 1\n",
            "and 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoiBmO_AF5FF",
        "colab_type": "text"
      },
      "source": [
        "ADDING 4 MORE NEW KEYS WITH THEIR RESPECTIVE VALUES WHICH WILL BE VERY HELP FULL IN ENCODING THE NEW REVIEW ALSO WE ADD +3 TO EVERY VALUES PRESENT IN THE WORDS SO THAT WE CAN MAKE PLACE FOR OUR NEW (KEY,VALUE) PAIRS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXWXqTLX-4lt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word={k:v+3 for k,v in word.items()}\n",
        "word[\"<PAD>\"]=0\n",
        "word[\"<START>\"]=1\n",
        "word[\"<UNK>\"]=2\n",
        "word[\"<UNUSED>\"]=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbqYusH8FuKD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "a56c99aa-cbb1-48fd-9365-ec52f135910f"
      },
      "source": [
        "for i,j in word.items():\n",
        "  if j==0:\n",
        "    print(i,j)\n",
        "  if j==1:\n",
        "    print(i,j)\n",
        "  if j==2:\n",
        "    print(i,j)\n",
        "  if j==3:\n",
        "    print(i,j)\n",
        "print(word['a'])\n",
        "print(word['the'])\n",
        "print(word['and'])"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PAD> 0\n",
            "<START> 1\n",
            "<UNK> 2\n",
            "<UNUSED> 3\n",
            "6\n",
            "4\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu82W4eSG2FI",
        "colab_type": "text"
      },
      "source": [
        "CREATING DICTIONERY WITH KEY AS INDEX AND VALUE AS UNIQUE WORD SO TO DECODE THE REVIEW SO THAT WE CAN READ IT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IWJEuxE-4qc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reversed_word=dict([(value,key) for (key,value) in word.items()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_rL-QX6-4oS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_words=6000\n",
        "(x_train,y_train),(x_test,y_test)=data.load_data(num_words=top_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zorwGiHDC1YU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "1e96392c-2143-4ec7-8681-7719201f0fe1"
      },
      "source": [
        "def decode_data(text):\n",
        "    return \" \".join([reversed_word.get(i) for i in text])\n",
        "print(decode_data(x_train[1]))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<START> big hair big <UNK> bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an <UNK> the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are <UNK> and funny in equal <UNK> the hair is big lots of <UNK> <UNK> men wear those cut <UNK> <UNK> that show off their <UNK> <UNK> that men actually wore them and the music is just <UNK> trash that plays over and over again in almost every scene there is trashy music <UNK> and <UNK> taking away bodies and the <UNK> still doesn't close for <UNK> all <UNK> aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acgYIrb0C3MB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "3b33fd7e-c3d7-4411-8678-1432b14599ce"
      },
      "source": [
        "print(\"Length of Train Data is\",len(x_train))\n",
        "print(\"Length of Test Data is\",len(x_train))\n",
        "print(\"First word vector looks like\",x_train[1])\n",
        "print(\"Data Type of Word Vector\",type(x_train[1]))\n",
        "print(\"Length of Word Vector\",len(x_train[1]))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Train Data is 25000\n",
            "Length of Test Data is 25000\n",
            "First word vector looks like [1, 194, 1153, 194, 2, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 2, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 2, 2, 349, 2637, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 2, 5, 2, 656, 245, 2350, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n",
            "Data Type of Word Vector <class 'list'>\n",
            "Length of Word Vector 189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oybY7gtJJbnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Padding the Word Vectors\n",
        "max_length = 500\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=max_length)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZLp6Vw2Jb6f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "outputId": "54e92258-0e83-4085-c33e-1c5d52e788a6"
      },
      "source": [
        "print(\"After padding the shape of word vector\",x_train.shape)\n",
        "print(x_train[1])"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After padding the shape of word vector (25000, 500)\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    1  194 1153  194    2   78  228    5    6 1463 4369\n",
            " 5012  134   26    4  715    8  118 1634   14  394   20   13  119  954\n",
            "  189  102    5  207  110 3103   21   14   69  188    8   30   23    7\n",
            "    4  249  126   93    4  114    9 2300 1523    5  647    4  116    9\n",
            "   35    2    4  229    9  340 1322    4  118    9    4  130 4901   19\n",
            "    4 1002    5   89   29  952   46   37    4  455    9   45   43   38\n",
            " 1543 1905  398    4 1649   26    2    5  163   11 3215    2    4 1153\n",
            "    9  194  775    7    2    2  349 2637  148  605    2    2   15  123\n",
            "  125   68    2    2   15  349  165 4362   98    5    4  228    9   43\n",
            "    2 1157   15  299  120    5  120  174   11  220  175  136   50    9\n",
            " 4373  228    2    5    2  656  245 2350    5    4    2  131  152  491\n",
            "   18    2   32    2 1212   14    9    6  371   78   22  625   64 1382\n",
            "    9    8  168  145   23    4 1690   15   16    4 1355    5   28    6\n",
            "   52  154  462   33   89   78  285   16  145   95]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqAUydfQJFUB",
        "colab_type": "text"
      },
      "source": [
        "CREATING NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1QouFJGJcH_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "d24546ac-0136-43aa-8542-47c857fccd37"
      },
      "source": [
        "embedding_vecor_length = 64\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_length))\n",
        "model.add(LSTM(200))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 500, 64)           384000    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 200)               212000    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 596,201\n",
            "Trainable params: 596,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia71JHYnJJPk",
        "colab_type": "text"
      },
      "source": [
        "TRAINING NETWORK AND ALSO FINDING ACCURACY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihmuqyaCJcUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "outputId": "b40392b7-0c8a-4519-d22e-855704786e31"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=20, batch_size=64)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "25000/25000 [==============================] - 299s 12ms/step - loss: 0.1209 - accuracy: 0.9569\n",
            "Epoch 2/20\n",
            "25000/25000 [==============================] - 298s 12ms/step - loss: 0.1098 - accuracy: 0.9609\n",
            "Epoch 3/20\n",
            "25000/25000 [==============================] - 299s 12ms/step - loss: 0.1013 - accuracy: 0.9654\n",
            "Epoch 4/20\n",
            "25000/25000 [==============================] - 298s 12ms/step - loss: 0.0862 - accuracy: 0.9703\n",
            "Epoch 5/20\n",
            "25000/25000 [==============================] - 298s 12ms/step - loss: 0.0537 - accuracy: 0.9830\n",
            "Epoch 6/20\n",
            "25000/25000 [==============================] - 299s 12ms/step - loss: 0.0635 - accuracy: 0.9794\n",
            "Epoch 7/20\n",
            "25000/25000 [==============================] - 299s 12ms/step - loss: 0.0625 - accuracy: 0.9788\n",
            "Epoch 8/20\n",
            "25000/25000 [==============================] - 299s 12ms/step - loss: 0.0485 - accuracy: 0.9844\n",
            "Epoch 9/20\n",
            "25000/25000 [==============================] - 299s 12ms/step - loss: 0.0279 - accuracy: 0.9919\n",
            "Epoch 10/20\n",
            "25000/25000 [==============================] - 304s 12ms/step - loss: 0.0540 - accuracy: 0.9833\n",
            "Epoch 11/20\n",
            "25000/25000 [==============================] - 305s 12ms/step - loss: 0.0283 - accuracy: 0.9908\n",
            "Epoch 12/20\n",
            "25000/25000 [==============================] - 304s 12ms/step - loss: 0.0154 - accuracy: 0.9954\n",
            "Epoch 13/20\n",
            "25000/25000 [==============================] - 301s 12ms/step - loss: 0.0394 - accuracy: 0.9866\n",
            "Epoch 14/20\n",
            "25000/25000 [==============================] - 301s 12ms/step - loss: 0.0302 - accuracy: 0.9910\n",
            "Epoch 15/20\n",
            "25000/25000 [==============================] - 300s 12ms/step - loss: 0.0171 - accuracy: 0.9952\n",
            "Epoch 16/20\n",
            "25000/25000 [==============================] - 301s 12ms/step - loss: 0.0139 - accuracy: 0.9960\n",
            "Epoch 17/20\n",
            "25000/25000 [==============================] - 300s 12ms/step - loss: 0.0373 - accuracy: 0.9880\n",
            "Epoch 18/20\n",
            "25000/25000 [==============================] - 302s 12ms/step - loss: 0.0148 - accuracy: 0.9957\n",
            "Epoch 19/20\n",
            "25000/25000 [==============================] - 301s 12ms/step - loss: 0.0211 - accuracy: 0.9934\n",
            "Epoch 20/20\n",
            "25000/25000 [==============================] - 301s 12ms/step - loss: 0.0545 - accuracy: 0.9812\n",
            "Accuracy: 85.45%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-D5-iMuJcqa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5a96bc4f-2ab2-4b02-b85d-5db5d2f6c902"
      },
      "source": [
        "model"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f2d30356fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmbAz4UkJc53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_review(r):\n",
        "    encode=[1]\n",
        "    r=r.split()\n",
        "    for i in r:\n",
        "        if i in word:\n",
        "            encode.append(word[i])\n",
        "        else:\n",
        "            encode.append(2)\n",
        "    return encode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY3WD1N7HTQS",
        "colab_type": "text"
      },
      "source": [
        "PREDECTING THE OUPUT OF OUR GIVEN REVIEW AND ENCODING IT SO AS TO SEND IT INTO THE EMBEDDING LAYER WHICH IS FIRST LAYER OF LSTM NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1OtcyXnJdN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_review=\"The movie was so good and it is a romatic moive and this movie is one of the best movie of my entire life\"\n",
        "reviews=[encode_review(input_review)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ5QPS5FH1va",
        "colab_type": "text"
      },
      "source": [
        "SINCE WE ALSO NEED TO MATCH THE SIZE OF EMBEDDING LAYER WE DO PADDING HERE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi_R2ARMyyRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_values=sequence.pad_sequences(reviews,value=word[\"<PAD>\"],padding=\"pre\",maxlen=max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iCePaFayylj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ecb26c8e-7a3c-4b81-a661-95e3ba3b77e2"
      },
      "source": [
        "model.predict(encoded_values)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99701774]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M4pfq5zIEVJ",
        "colab_type": "text"
      },
      "source": [
        "SAVING MODEL FOR FUTURE USUAGE AND LOADING IT BACK TO CHECK IF IT IS WORKING PROPERLY OR NOT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsppIl9R2-iN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"Sentimental_Lstm.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGYfx77k3PBa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "5384a05a-94ff-41d9-cffe-44b00c6c5799"
      },
      "source": [
        "from keras.models import load_model\n",
        "model1=load_model(\"Sentimental_Lstm.h5\")\n",
        "model1"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f2d35e69b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji220aM23euk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9d3111b9-46c1-4d62-8709-487908378f30"
      },
      "source": [
        "model1.predict(encoded_values)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99701774]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCQYwEhsFfNQ",
        "colab_type": "text"
      },
      "source": [
        "**SO HERE THE OUTPUT IS THERE IS 99% CHANCE THAT IS POSITIVE TEXT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBjchhz_ITMJ",
        "colab_type": "text"
      },
      "source": [
        "ALSO SAVING WORD DICTONERY IN JSON FILE AS IT IS REQUIRED FOR ENCODING THE REVIEW "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJYl8pP64CQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import torch\n",
        "with open('sentimental.json', 'w') as f:\n",
        "      json.dump(word, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lADSdUHbRNIH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "outputId": "d4616c46-e381-4ed8-a082-5c8b7cefab27"
      },
      "source": [
        "import pandas as pd\n",
        "data=[[\"LSTM(RNN)\",200, 1,20,64,85.45]]\n",
        "pd.DataFrame(data,columns=[\"Model\"  ,\"Number_Of_Models(LSTMS)\",  \"Number_Of_Hidden_Layers\",  \"Epochs\",\"Batch-Size\",  \"Accuracy(%)\"])"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Number_Of_Models(LSTMS)</th>\n",
              "      <th>Number_Of_Hidden_Layers</th>\n",
              "      <th>Epochs</th>\n",
              "      <th>Batch-Size</th>\n",
              "      <th>Accuracy(%)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LSTM(RNN)</td>\n",
              "      <td>200</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>64</td>\n",
              "      <td>85.45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Model  Number_Of_Models(LSTMS)  ...  Batch-Size  Accuracy(%)\n",
              "0  LSTM(RNN)                      200  ...          64        85.45\n",
              "\n",
              "[1 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    }
  ]
}